# ========================================
# Flask å¾Œç«¯æ‡‰ç”¨ç¨‹å¼
# ========================================
# åŠŸèƒ½ï¼š
# - å‰ç«¯éŸ³è¨Šä¸Šå‚³æ¥æ”¶
# - Azure STT èªéŸ³è½‰æ–‡å­—
# - Gemini LLM å°è©±
# - Azure TTS æ–‡å­—è½‰èªéŸ³
# - æ—¥èªŒè¿½è¹¤

import os
import uuid
import time
import traceback
import json
import subprocess
import shutil
from pathlib import Path
from threading import Lock
import logging

from flask import Flask, request, jsonify, send_file, abort, Response
from dotenv import load_dotenv
import azure.cognitiveservices.speech as speechsdk

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# å¼•å…¥æ ¸å¿ƒé‚è¼¯
import core_logic

# ==================== æ—¥èªŒè¨­å®š ====================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('beauty_bot.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ==================== Flask æ‡‰ç”¨è¨­å®š ====================
app = Flask(__name__)
app.config["JSON_AS_ASCII"] = False
app.config["MAX_CONTENT_LENGTH"] = 25 * 1024 * 1024

HOST = "0.0.0.0"
PORT = int(os.getenv("PORT", "5001"))

# ==================== Azure èªéŸ³è¨­å®š ====================
AZURE_SPEECH_KEY = os.getenv("AZURE_SPEECH_KEY")
AZURE_SPEECH_REGION = os.getenv("AZURE_SPEECH_REGION", "eastasia")

if not AZURE_SPEECH_KEY or not AZURE_SPEECH_REGION:
    raise RuntimeError("âŒ è«‹è¨­å®š AZURE_SPEECH_KEY åŠ AZURE_SPEECH_REGION")

VOICE_NAME = getattr(core_logic, "VOICE_NAME", "zh-HK-HiuMaanNeural")

# ==================== è‡¨æ™‚ç›®éŒ„è¨­å®š ====================
TMP_DIR = Path(os.getenv("FLASK_TMP_DIR", "./flask_tmp"))
TMP_DIR.mkdir(parents=True, exist_ok=True)

# ==================== èªéŸ³é…ç½®ï¼ˆSTT / TTS åˆ†é›¢ï¼‰ ====================
speech_config_stt = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_SPEECH_REGION)
speech_config_stt.speech_recognition_language = "zh-HK"

speech_config_tts = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_SPEECH_REGION)
speech_config_tts.speech_synthesis_language = "zh-HK"
speech_config_tts.speech_synthesis_voice_name = VOICE_NAME
speech_config_tts.set_speech_synthesis_output_format(
    speechsdk.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3
)

_TTS_LOCK = Lock()

# ==================== å·¥å…·å‡½æ•¸ ====================

def _now():
    """å–å¾—ç•¶å‰æ™‚é–“æˆ³ï¼ˆç§’ï¼‰ï¼Œç”¨æ–¼è¨ˆæ™‚"""
    return time.perf_counter()


def _ensure_ffmpeg():
    """æª¢æŸ¥ ffmpeg ä¿‚å¦å®‰è£"""
    if shutil.which("ffmpeg") is None:
        raise RuntimeError("âŒ ffmpeg æœªå®‰è£æˆ–æœªåŠ å…¥ PATH")


def convert_to_wav(src:  Path, dst: Path):
    """ç”¨ ffmpeg å°‡ webm è½‰æˆ wavï¼ˆ16kHz, mono, PCMï¼‰"""
    _ensure_ffmpeg()
    cmd = [
        "ffmpeg", "-y",
        "-nostdin", "-hide_banner", "-loglevel", "error",
        "-threads", "2",
        "-i", str(src),
        "-vn",
        "-ac", "1",
        "-ar", "16000",
        "-c:a", "pcm_s16le",
        str(dst)
    ]
    p = subprocess.run(cmd, capture_output=True, text=True, timeout=25)
    if p.returncode != 0:
        raise RuntimeError(f"ffmpeg è½‰æ›å¤±æ•—ï¼š{p.stderr[-500:] if p.stderr else 'æœªçŸ¥éŒ¯èª¤'}")


def stt_from_wav(wav_path: Path) -> str:
    """Azure STTï¼šå°‡ wav æª”è½‰æ›ç‚ºå»£æ±è©±æ–‡å­—"""
    try:
        audio_cfg = speechsdk.audio.AudioConfig(filename=str(wav_path))
        recog = speechsdk.SpeechRecognizer(speech_config_stt, audio_cfg)
        r = recog.recognize_once_async().get()

        if r.reason == speechsdk.ResultReason.RecognizedSpeech:
            return (r.text or "").strip()

        if r.reason == speechsdk. ResultReason.NoMatch:
            logger.warning("STTï¼šè½å””åˆ°èªªè©±")
            return ""

        if r.reason == speechsdk.ResultReason.Canceled:
            logger.error(f"STT è¢«å–æ¶ˆï¼š{r.cancellation_details. error_details}")
            return ""

        return ""
    except Exception as e: 
        logger.error(f"STT ç•°å¸¸ï¼š{e}", exc_info=True)
        return ""


def tts_to_mp3(text: str, out:  Path) -> tuple[bool, str]:
    """
    Azure TTSï¼šå°‡æ–‡å­—è½‰æˆ MP3 èªéŸ³æª”
    è¿”å› (æˆåŠŸå¦, éŒ¯èª¤è¨Šæ¯)
    """
    # æ¸…ç†æ–‡å­—
    t = core_logic.sanitize_tts_text(text) if hasattr(core_logic, 'sanitize_tts_text') else (text or "")
    t = t.strip()

    if not t:
        return False, "æ–‡å­—ç‚ºç©º"

    # é™åˆ¶é•·åº¦ï¼ˆåŠ å¿« TTSï¼‰
    max_chars = int(os.getenv("MAX_REPLY_CHARS", "180"))
    if len(t) > max_chars:
        t = t[:max_chars]

    try:
        if out.exists():
            out.unlink()
    except Exception: 
        pass

    try: 
        audio_cfg = speechsdk.audio.AudioOutputConfig(filename=str(out))
        synth = speechsdk.SpeechSynthesizer(speech_config_tts, audio_cfg)

        with _TTS_LOCK:
            r = synth.speak_text_async(t).get()

        if r.reason == speechsdk.ResultReason.SynthesizingAudioCompleted and out.exists() and out.stat().st_size > 0:
            return True, ""

        if r.reason == speechsdk.ResultReason.Canceled:
            err = r.cancellation_details. error_details if r.cancellation_details else "æœªçŸ¥"
            logger.error(f"TTS è¢«å–æ¶ˆï¼š{err}")
            return False, f"TTS å¤±æ•—ï¼š{err}"

        logger.error(f"TTS æœªå®Œæˆï¼š{r.reason}")
        return False, f"TTS å¤±æ•—ï¼š{r.reason}"

    except Exception as e:
        logger.error(f"TTS ç•°å¸¸ï¼š{e}", exc_info=True)
        return False, str(e)


def _safe_delete(p: Path):
    """å®‰å…¨åˆªé™¤æª”æ¡ˆ"""
    try:
        if p and p.exists():
            p.unlink()
    except Exception:
        pass


# ==================== API ç«¯é» ====================

@app.post("/api/voice")
def api_voice():
    """ä¸» APIï¼šæ¥æ”¶éŸ³è¨Šã€è½‰éŒ„ã€ç”Ÿæˆå›è¦†ã€åˆæˆèªéŸ³"""
    request_id = uuid.uuid4().hex[: 8]
    logger.info(f"[{request_id}] æ–°è«‹æ±‚é–‹å§‹")

    t0 = _now()
    webm_path = wav_path = None

    try: 
        # 1ï¸âƒ£ å–å¾—ä¸Šå‚³å˜…éŸ³è¨Šæª”
        f = request.files. get("audio")
        if not f or not f.filename:
            logger.warning(f"[{request_id}] ç„¡éŸ³è¨Šæª”")
            return jsonify(ok=False, error="æ²’æœ‰ä¸Šå‚³éŸ³è¨Šæª”"), 400

        # 2ï¸âƒ£ å–å¾—å°è©±ç‹€æ…‹
        state_str = request.form.get("state", "{}")
        try:
            current_state = json.loads(state_str)
        except json. JSONDecodeError:
            current_state = {}

        # 3ï¸âƒ£ å„²å­˜ä¸Šå‚³å˜…æª”æ¡ˆä¸¦è½‰æ›
        rid = uuid.uuid4().hex
        webm_path = TMP_DIR / f"in_{rid}.webm"
        wav_path = TMP_DIR / f"in_{rid}.wav"

        f.save(webm_path)
        logger.info(f"[{request_id}] æª”æ¡ˆå·²å„²å­˜ï¼š{webm_path. name}")

        t_a = _now()
        convert_to_wav(webm_path, wav_path)
        t_conv = _now() - t_a
        logger.info(f"[{request_id}] è½‰æ›è€—æ™‚ï¼š{t_conv:. 2f}s")

        # 4ï¸âƒ£ èªéŸ³è½‰æ–‡å­— (STT)
        t_b = _now()
        user_text = stt_from_wav(wav_path)
        t_stt = _now() - t_b

        if not user_text:
            logger.warning(f"[{request_id}] STT ç„¡çµæœ")
            return jsonify(
                ok=False,
                error="ç„¡æ³•è­˜åˆ¥èªéŸ³",
                state=current_state,
                timing=f"{_now()-t0:.1f}s"
            ), 400

        logger.info(f"[{request_id}] STT å®Œæˆï¼š'{user_text[: 50]}'...  (è€—æ™‚ {t_stt:.2f}s)")

        # 5ï¸âƒ£ ç”Ÿæˆ AI å›è¦†
        t_c = _now()
        reply_text, new_state = core_logic.generate_reply(user_text, current_state)
        t_llm = _now() - t_c

        if not reply_text:
            reply_text = "å””å¥½æ„æ€ï¼Œæˆ‘é ­å…ˆè½å””æ¸…æ¥šï¼Œå¯ä»¥å†è¬›ä¸€æ¬¡å—ï¼Ÿ"

        logger.info(f"[{request_id}] AI å›è¦†è€—æ™‚ï¼š{t_llm:.2f}sï¼Œå›è¦†ï¼š'{reply_text[:50]}'...")

        # 6ï¸âƒ£ æ–‡å­—è½‰èªéŸ³ (TTS)
        mp3_path = TMP_DIR / f"tts_{rid}.mp3"
        t_d = _now()
        tts_ok, tts_err = tts_to_mp3(reply_text, mp3_path)
        t_tts = _now() - t_d

        logger.info(f"[{request_id}] TTS è€—æ™‚ï¼š{t_tts:.2f}sï¼ŒæˆåŠŸï¼š{tts_ok}")

        # 7ï¸âƒ£ å›å‚³çµæœ
        total_time = _now() - t0
        logger.info(f"[{request_id}] ç¸½è€—æ™‚ï¼š{total_time:.2f}s")

        return jsonify(
            ok=True,
            tts_ok=tts_ok,
            tts_error=tts_err,
            user_text=user_text,
            reply_text=reply_text,
            audio_url=(f"/tts/{mp3_path.name}" if tts_ok else ""),
            state=new_state,
            timing=f"{total_time:.1f}s"
        )

    except Exception as e: 
        logger.error(f"[{request_id}] ç•°å¸¸ï¼š{str(e)}", exc_info=True)
        state_str = request.form.get("state", "{}")
        try:
            current_state = json.loads(state_str)
        except json.JSONDecodeError:
            current_state = {}
        return jsonify(ok=False, error=str(e), state=current_state), 500

    finally:
        _safe_delete(webm_path)
        _safe_delete(wav_path)


@app.post("/api/reset")
def api_reset():
    """é‡ç½®å°è©±è¨˜æ†¶"""
    try:
        new_state = core_logic.reset_memory()
        logger.info("å°è©±è¨˜æ†¶å·²é‡ç½®")
        return jsonify(ok=True, state=new_state)
    except Exception as e: 
        logger.error(f"é‡ç½®è¨˜æ†¶å¤±æ•—ï¼š{e}")
        return jsonify(ok=False, error=str(e)), 500


@app.get("/tts/<name>")
def tts_file(name):
    """æ’­æ”¾ TTS èªéŸ³æª”"""
    if not name.startswith("tts_") or not name.endswith(".mp3"):
        abort(404)
    p = TMP_DIR / name
    if not p.is_file():
        abort(404)
    return send_file(p, mimetype="audio/mpeg", conditional=True)


# ==================== å‰ç«¯ HTML ====================

HTML_PAGE = r"""<! doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>ç¾å®¹é™¢ ç²µèª AI æ¥ç·šç”Ÿ Demo</title>
  <style>
    * { box-sizing: border-box; }
    body {
      font-family: system-ui, -apple-system, "Segoe UI", Roboto, "Noto Sans HK", "PingFang HK", Arial, sans-serif;
      max-width: 800px;
      margin: 0 auto;
      padding: 20px;
      background:  linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      min-height: 100vh;
    }
    .container {
      background: white;
      border-radius: 16px;
      padding: 24px;
      box-shadow:  0 20px 60px rgba(0,0,0,0.3);
    }
    h1 {
      color: #d63384;
      margin:  0 0 8px;
      font-size: 36px;
    }
    .subtitle {
      color: #666;
      margin: 0 0 20px;
      font-size:  14px;
    }
    . feature-grid {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 12px;
      margin-bottom: 20px;
    }
    . feature-card {
      background:  #f0f8ff;
      border-left: 4px solid #28a745;
      padding: 10px 12px;
      border-radius:  6px;
      font-size: 12px;
      color: #333;
    }
    .controls {
      display: flex;
      gap: 8px;
      margin-bottom:  20px;
      flex-wrap: wrap;
    }
    button {
      padding: 12px 16px;
      border: none;
      border-radius: 8px;
      font-size: 14px;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.3s;
    }
    #btnStart {
      background: #28a745;
      color: white;
    }
    #btnStart:hover: not(:disabled) {
      background: #218838;
    }
    #btnStop {
      background: #dc3545;
      color:  white;
    }
    #btnStop:hover:not(:disabled) {
      background: #c82333;
    }
    #btnReset {
      background: #6c757d;
      color: white;
    }
    #btnReset:hover:not(:disabled) {
      background: #5a6268;
    }
    button:disabled {
      opacity: 0.5;
      cursor: not-allowed;
    }
    .status-bar {
      display: flex;
      gap: 12px;
      align-items: center;
      margin-bottom: 20px;
      padding: 12px;
      background: #f8f9fa;
      border-radius: 8px;
      font-size: 13px;
    }
    #status {
      font-weight: 600;
      color: #333;
      flex:  1;
    }
    #timing {
      font-family: monospace;
      font-weight: bold;
      color: #dc3545;
      display: none;
    }
    #timing.active {
      display: inline;
    }
    .content-grid {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 16px;
      margin-bottom: 20px;
    }
    .content-box {
      border: 1px solid #e0e0e0;
      border-radius: 8px;
      padding: 12px;
    }
    .content-box h3 {
      margin:  0 0 8px;
      font-size: 13px;
      color: #666;
      font-weight: 600;
    }
    .content-box . text {
      min-height: 60px;
      padding: 8px;
      background: #fafafa;
      border-radius: 6px;
      font-size:  13px;
      line-height: 1.5;
      word-wrap: break-word;
    }
    .audio-section {
      margin-bottom: 20px;
    }
    .audio-section h3 {
      margin: 0 0 8px;
      font-size: 13px;
      color: #666;
      font-weight: 600;
    }
    audio {
      width: 100%;
      height: 32px;
    }
    #log {
      background: #1e1e1e;
      color:  #d7ffd7;
      padding: 12px;
      border-radius:  8px;
      font-family: "Courier New", monospace;
      font-size: 11px;
      max-height: 200px;
      overflow-y:  auto;
      white-space: pre-wrap;
      word-break: break-all;
      line-height: 1.4;
    }
    @media (max-width: 600px) {
      .content-grid {
        grid-template-columns: 1fr;
      }
      .feature-grid {
        grid-template-columns: 1fr;
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>ğŸ™‹â€â™€ï¸ ç²µèª AI æ¥ç·šç”Ÿ Demo</h1>
    <p class="subtitle">ç¾å®¹é™¢ç‰ˆæœ¬ v1.0 - è‡ªå‹•è™•ç†é ç´„ã€æŸ¥è©¢ã€ä»‹ç´¹</p>

    <div class="feature-grid">
      <div class="feature-card">âœ… ç²µèªè‡ªç„¶å°è©±</div>
      <div class="feature-card">âœ… <10ç§’å›æ‡‰</div>
      <div class="feature-card">âœ… æ™ºèƒ½è¨˜æ†¶å®¢æˆ¶</div>
      <div class="feature-card">âœ… é¿å…é‡è¤‡æå•</div>
    </div>

    <div class="controls">
      <button id="btnStart">ğŸ™ï¸ é–‹å§‹éŒ„éŸ³</button>
      <button id="btnStop" disabled>â¹ï¸ åœæ­¢ä¸¦é€å‡º</button>
      <button id="btnReset">ğŸ§¼ æ¸…ç©ºè¨˜æ†¶</button>
    </div>

    <div class="status-bar">
      <span id="status">æº–å‚™å°±ç·’</span>
      <span id="timing">â±ï¸ 0. 0s</span>
    </div>

    <div class="content-grid">
      <div class="content-box">
        <h3>ğŸ‘¤ ä½ è¬›å˜…ï¼š</h3>
        <div id="sttText" class="text"></div>
      </div>
      <div class="content-box">
        <h3>ğŸ¤– æ¥ç·šç”Ÿå›è¦†ï¼š</h3>
        <div id="replyText" class="text"></div>
      </div>
    </div>

    <div class="audio-section">
      <h3>ğŸ”Š èªéŸ³å›è¦†ï¼š</h3>
      <audio id="player" controls></audio>
    </div>

    <div style="margin-top: 16px;">
      <h3 style="font-size: 13px; color: #666; margin:  0 0 8px;">ğŸ“‹ ç³»çµ±æ—¥èªŒï¼š</h3>
      <pre id="log"></pre>
    </div>
  </div>

<script>
const $ = (id) => document.getElementById(id);

let stream = null;
let mediaRecorder = null;
let chunks = [];
let conversationState = {};
let recordStartTime = 0;

function log(msg) {
  const now = new Date().toLocaleTimeString();
  $("log").textContent = `[${now}] ${msg}\n` + $("log").textContent;
}

function pickMimeType() {
  const candidates = [
    "audio/webm;codecs=opus",
    "audio/webm",
    "audio/ogg;codecs=opus",
    "audio/ogg"
  ];
  for (const t of candidates) {
    if (MediaRecorder.isTypeSupported && MediaRecorder.isTypeSupported(t)) return t;
  }
  return "";
}

async function initMic() {
  try {
    if (!(window.isSecureContext || location.hostname === "localhost" || location.hostname === "127.0.0.1")) {
      $("status").textContent = "âš ï¸ éœ€è¦ HTTPS æˆ– localhost";
      log("Not secure context");
      return;
    }
    stream = await navigator.mediaDevices. getUserMedia({ audio: true });
    $("status").textContent = "âœ… éº¥å…‹é¢¨å°±ç·’";
    $("btnStart").disabled = false;
    log("âœ… éº¥å…‹é¢¨å·²æˆæ¬Š");
  } catch (e) {
    $("status").textContent = "âŒ éº¥å…‹é¢¨æˆæ¬Šå¤±æ•—";
    log("âŒ éº¥å…‹é¢¨éŒ¯èª¤ï¼š" + e);
  }
}

initMic();

$("btnStart").onclick = async () => {
  try {
    if (!stream) {
      await initMic();
      if (!stream) return;
    }
    chunks = [];
    const mimeType = pickMimeType();
    const opts = { audioBitsPerSecond: 64000 };
    if (mimeType) opts.mimeType = mimeType;

    mediaRecorder = new MediaRecorder(stream, opts);

    mediaRecorder.ondataavailable = (e) => {
      if (e.data && e.data.size > 0) chunks.push(e.data);
    };

    mediaRecorder. onstart = () => {
      recordStartTime = Date.now();
      $("status").textContent = "ğŸ”´ éŒ„éŸ³ä¸­â€¦";
      $("btnStart").disabled = true;
      $("btnStop").disabled = false;
      log("â–¶ï¸ éŒ„éŸ³é–‹å§‹");
    };

    mediaRecorder.onstop = async () => {
      $("status").textContent = "â³ è™•ç†ä¸­ï¼Œè«‹ç¨å€™â€¦";
      $("btnStop").disabled = true;
      $("timing").classList.add("active");

      const blob = new Blob(chunks, { type: mediaRecorder.mimeType || "audio/webm" });
      log(`ğŸ“¦ éŒ„éŸ³å®Œæˆï¼Œå¤§å°ï¼š${(blob.size / 1024).toFixed(1)} KB`);

      const fd = new FormData();
      fd.append("audio", blob, "recording.webm");
      fd.append("state", JSON.stringify(conversationState));

      try {
        const controller = new AbortController();
        const timer = setTimeout(() => controller.abort(), 30000);

        const res = await fetch("/api/voice", {
          method: "POST",
          body: fd,
          signal: controller.signal
        });

        clearTimeout(timer);

        const j = await res.json();

        if (j.state) {
          conversationState = j.state;
        }

        if (! j.ok) {
          $("status").textContent = `âŒ å¤±æ•—ï¼š${j.error}`;
          log("âŒ API éŒ¯èª¤ï¼š" + (j.error || "æœªçŸ¥"));
          $("btnStart").disabled = false;
          $("timing").classList.remove("active");
          return;
        }

        $("sttText").textContent = j.user_text || "ï¼ˆæœªèƒ½è­˜åˆ¥ï¼‰";
        $("replyText").textContent = j.reply_text || "";
        $("player").src = j.audio_url || "";
        $("status").textContent = `âœ… å®Œæˆ (${j.timing})`;
        log(`âœ… ç¸½è€—æ™‚ï¼š${j.timing}`);
        log(`ğŸ“ å®¢äººï¼š${j.user_text || "ï¼ˆç„¡ï¼‰"}`);
        log(`ğŸ¤– å›è¦†ï¼š${j.reply_text || "ï¼ˆç„¡ï¼‰"}`);

        try {
          await $("player").play();
          log("ğŸ”Š æ­£åœ¨æ’­æ”¾èªéŸ³");
        } catch (e) {
          log("âš ï¸ æ’­æ”¾å¤±æ•—ï¼š" + e);
        }

        $("btnStart").disabled = false;
        $("timing").classList.remove("active");

      } catch (e) {
        $("status").textContent = "âŒ ä¸Šå‚³å¤±æ•—";
        log("âŒ ä¸Šå‚³éŒ¯èª¤ï¼š" + e);
        $("btnStart").disabled = false;
        $("timing").classList.remove("active");
      }
    };

    mediaRecorder.start();

  } catch (e) {
    $("status").textContent = "âŒ éŒ„éŸ³å¤±æ•—";
    log("âŒ éŒ„éŸ³éŒ¯èª¤ï¼š" + e);
    $("btnStart").disabled = false;
  }
};

$("btnStop").onclick = () => {
  try {
    if (mediaRecorder && mediaRecorder.state === "recording") {
      mediaRecorder. stop();
      log("â¹ï¸ æ‰‹å‹•åœæ­¢éŒ„éŸ³");
    }
  } catch (e) {
    log("âŒ åœæ­¢éŒ¯èª¤ï¼š" + e);
  }
};

$("btnReset").onclick = async () => {
  try {
    const r = await fetch("/api/reset", { method:  "POST" });
    const j = await r.json();
    if (j.ok) {
      conversationState = j.state || {};
      $("sttText").textContent = "";
      $("replyText").textContent = "";
      $("player").src = "";
      log("ğŸ§¼ å°è©±è¨˜æ†¶å·²æ¸…ç©º");
      $("status").textContent = "âœ… è¨˜æ†¶å·²æ¸…ç©ºï¼Œå¯ä»¥é–‹å§‹æ–°å°è©±";
    } else {
      log("âŒ æ¸…ç©ºå¤±æ•—ï¼š" + (j.error || "æœªçŸ¥éŒ¯èª¤"));
    }
  } catch (e) {
    log("âŒ æ¸…ç©ºéŒ¯èª¤ï¼š" + e);
  }
};

// å³æ™‚è¨ˆæ™‚é¡¯ç¤ºï¼ˆç”¨æ–¼ UX åé¥‹ï¼‰
setInterval(() => {
  if ($("status").textContent.includes("è™•ç†ä¸­")) {
    let elapsed = ((Date.now() - recordStartTime) / 1000).toFixed(1);
    $("timing").textContent = `â±ï¸ ${elapsed}s`;
  }
}, 100);
</script>
</body>
</html>
"""

@app.get("/")
def index():
    """ä¸»é é¢"""
    return Response(HTML_PAGE, mimetype="text/html")


if __name__ == "__main__": 
    try:
        _ensure_ffmpeg()
        logger.info("âœ… ffmpeg æª¢æŸ¥é€šé")
        logger.info(f"ğŸš€ Flask æ‡‰ç”¨å•Ÿå‹•ï¼šhttp://{HOST}:{PORT}")
        logger.info(f"ğŸ“ Azure å€åŸŸï¼š{AZURE_SPEECH_REGION}")
        app.run(host=HOST, port=PORT, debug=False, threaded=True)
    except RuntimeError as e:
        logger. error(f"âŒ å•Ÿå‹•éŒ¯èª¤ï¼š{e}")